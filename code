import pandas as pd
import numpy as np
import re
import string
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# Download stopwords if not already present
nltk.download('stopwords')

# Mount Google Drive to access the dataset
from google.colab import drive
drive.mount('/content/drive')

# Load dataset from Google Drive
df = pd.read_csv('/content/drive/My Drive/datasets/spam_ham_dataset.csv', encoding='latin-1')

# Check the column names of the dataset
print(df.columns)

# Drop the unnecessary 'Unnamed: 0' and 'label_num' columns
df = df[['label', 'text']]  # Keep only 'label' and 'text'
df.columns = ['label', 'message']  # Rename 'text' to 'message'

# Convert labels: 'spam' -> 1, 'ham' -> 0
df['label'] = df['label'].map({'ham': 0, 'spam': 1})

# Initialize stemmer and stopwords
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    """Function to preprocess text: lowercasing, removing digits, punctuation, stopwords, and stemming."""
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation
    words = text.split()  # Tokenize
    words = [stemmer.stem(word) for word in words if word not in stop_words]  # Stemming & stopword removal
    return ' '.join(words)

# Apply preprocessing to the dataset
df['clean_message'] = df['message'].apply(preprocess_text)

# Split data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(df['clean_message'], df['label'], test_size=0.2, random_state=42)

# Convert text into numerical features using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)  # Limit to top 5000 features
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Train the model using Multinomial Naive Bayes
model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test_tfidf)

# Calculate and display accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')

# Print detailed classification report
print(classification_report(y_test, y_pred))

# Function to predict if a given email is spam or not
def predict_spam(email_text):
    email_text = preprocess_text(email_text)  # Preprocess the text
    email_vector = vectorizer.transform([email_text])  # Convert to TF-IDF
    prediction = model.predict(email_vector)  # Predict spam or ham
    return 'Spam' if prediction[0] == 1 else 'Ham'

# Example usage: Allow user to input their own email text
new_email = input("Enter your email text: ")  # Take user input for email text
print(f"Prediction: {predict_spam(new_email)}")  # Output: Spam or Ham
